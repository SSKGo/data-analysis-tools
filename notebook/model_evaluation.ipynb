{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# max_error is not available in V0.23.2 package, even it is in document \n",
    "# from sklearn.metrics import max_error\n",
    "\n",
    "# To take the version dependency in consideration\n",
    "# mean_absolute_percentage_error available after V0.24 is not used\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def calculte_score(y_actual: np.ndarray, y_estimated: np.ndarray) -> Dict[str, float]:\n",
    "    score_funcs = {\n",
    "        \"explained_variance\":{\"func\": explained_variance_score},\n",
    "        \"r2\": {\"func\": r2_score},\n",
    "        \"max_error\":{\"func\": None},\n",
    "        \"mean_absolute_error\":{\"func\": mean_absolute_error},\n",
    "        \"median_absolute_error\":{\"func\": median_absolute_error},\n",
    "        \"mean_squared_error\":{\"func\": mean_squared_error, \"squared\": True},\n",
    "        \"root_mean_squared_error\":{\"func\": mean_squared_error, \"squared\": False},\n",
    "        \"mean_absolute_percentage_error\":{\"func\": None},\n",
    "    }\n",
    "    scores = {}\n",
    "    for score_type, score_func in score_funcs.items():\n",
    "        if \"squared\" in score_func:\n",
    "            score_val = score_func[\"func\"](y_actual, y_estimated)\n",
    "            # TODO squared=False for RMSE instead of np.sqrt\n",
    "            if not score_func.get(\"squared\"):\n",
    "                score_val = np.sqrt(score_val)\n",
    "        elif score_type == \"max_error\":\n",
    "            abs_error = np.abs(y_estimated - y_actual)\n",
    "            score_val = np.max(abs_error, axis=0)[0]\n",
    "        elif score_type == \"mean_absolute_percentage_error\":\n",
    "            epsilon = np.finfo(np.float64).eps\n",
    "            abs_percent_error = np.abs(y_estimated - y_actual) / np.maximum(np.abs(y_actual), epsilon)\n",
    "            score_val = np.average(abs_percent_error, axis=0)[0]\n",
    "        else:\n",
    "            score_val = score_func[\"func\"](y_actual, y_estimated)\n",
    "        scores[score_type] = score_val\n",
    "    return scores\n",
    "\n",
    "def define_lim(*y_data) -> Tuple[float, float]:\n",
    "    y_all = np.vstack(y_data)\n",
    "    y_all[np.isinf(y_all)] = np.median(y_all)\n",
    "    lim_min, lim_max = np.min(y_all), np.max(y_all)\n",
    "    lim_width = abs(lim_max - lim_min)\n",
    "    lim_min -= lim_width * 0.1\n",
    "    lim_max += lim_width * 0.1\n",
    "    lim_min, lim_max\n",
    "    return lim_min, lim_max\n",
    "\n",
    "def draw_act_est_plot(ax, y_actual: np.ndarray, y_estimated: np.ndarray, axis_limit:Optional[Tuple[float, float]]=None, add_title:Optional[str]=None):\n",
    "    title = \"Actual-Estimate Plot\"\n",
    "    if add_title:\n",
    "        title += f\" {add_title}\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Actual\")\n",
    "    ax.set_ylabel(\"Estimated\")\n",
    "    if axis_limit:\n",
    "        lim_min, lim_max = axis_limit\n",
    "    else:\n",
    "        lim_min, lim_max = define_lim(y_actual, y_estimated)\n",
    "    ax.set_xlim(lim_min, lim_max)\n",
    "    ax.set_ylim(lim_min, lim_max)\n",
    "    for axis_type in [\"x\", \"y\"]:\n",
    "        ax.grid(which = \"major\", axis = axis_type, color = \"k\", alpha = 0.3,\n",
    "            linestyle = \"--\", linewidth = 1)\n",
    "    ax.plot([lim_min, lim_max], [lim_min, lim_max], color=\"k\", linewidth=0.5)\n",
    "    ax.scatter(y_actual, y_estimated, marker=\"o\")\n",
    "    return ax\n",
    "    \n",
    "def draw_score_table(ax, scores: Dict[str, float], add_title:Optional[str]=None):\n",
    "    ax.axis(\"off\")\n",
    "    title = \"Scores\"\n",
    "    if add_title:\n",
    "        title += f\" {add_title}\"\n",
    "    ax.set_title(title)\n",
    "    row_labels = []\n",
    "    cell_texts = []\n",
    "    for score_type, score_val in scores.items():\n",
    "        row_labels.append(score_type)\n",
    "        cell_texts.append([f\"{score_val:.3g}\"])\n",
    "    table = ax.table(cellText=cell_texts, rowLabels=row_labels, colLabels=[\"Scores\"], colWidths=[0.2], loc=\"best\")\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 1.5)\n",
    "    return ax\n",
    "\n",
    "def draw_q_q_plot(ax, y_actual: np.ndarray, y_estimated: np.ndarray, add_title:Optional[str]=None):\n",
    "    error = (y_estimated - y_actual).reshape(-1)\n",
    "    stats.probplot(error, dist=\"norm\", plot=ax)\n",
    "    title = \"Q-Q Plot\"\n",
    "    if add_title:\n",
    "        title += f\" {add_title}\"\n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "def draw_error_hist(ax, y_actual: np.ndarray, y_estimated: np.ndarray, bins:int=20, h_range:Optional[Tuple[float, float]]=None, add_title:Optional[str]=None):\n",
    "    title = \"Error Histogram\"\n",
    "    if add_title:\n",
    "        title += f\" {add_title}\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Error\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    error = (y_estimated - y_actual).reshape(-1)\n",
    "    ax.hist(error, bins=bins, range=h_range)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_figures(data_list, title:str=None):\n",
    "    n_data = len(data_list)\n",
    "\n",
    "    nrows, ncols = 4, n_data\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=n_data, figsize=(ncols * 5, nrows * 5), constrained_layout=True)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # Create common limit\n",
    "    y_all = []\n",
    "    error_all = []\n",
    "    for data_dict in data_list:\n",
    "        error_all.append(data_dict.get(\"estimated\") - data_dict.get(\"actual\"))\n",
    "        for data_type in [\"actual\", \"estimated\"]:\n",
    "            if isinstance(data_dict.get(data_type), np.ndarray):\n",
    "                y_all.append(data_dict.get(data_type))\n",
    "    y_limit = define_lim(*y_all)\n",
    "    error_limit = define_lim(*error_all)\n",
    "\n",
    "    for i_data, data_dict in enumerate(data_list):\n",
    "        name = data_dict.get(\"name\")\n",
    "        y_actual = data_dict.get(\"actual\")\n",
    "        y_estimated = data_dict.get(\"estimated\")\n",
    "        if (y_actual is not None) and (y_estimated is not None):\n",
    "            ax_targets = []\n",
    "            for i_ax in range(nrows):\n",
    "                ax_targets.append(axes[i_ax] if n_data == 1 else axes[i_ax, i_data])\n",
    "            scores = calculte_score(y_actual, y_estimated)\n",
    "            draw_act_est_plot(ax_targets[0], y_actual, y_estimated, axis_limit=y_limit, add_title=f\"[{name}]\")\n",
    "            draw_q_q_plot(ax_targets[1], y_actual, y_estimated, add_title=f\"[{name}]\")\n",
    "            draw_error_hist(ax_targets[2], y_actual, y_estimated, bins=40, h_range=error_limit, add_title=f\"[{name}]\")\n",
    "            draw_score_table(ax_targets[3], scores, add_title=f\"[{name}]\")\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_boston()\n",
    "x = dataset.data\n",
    "y_actual_org = dataset.target.reshape(-1, 1)\n",
    "y_estimated1 = y_actual_org + np.random.normal(loc=0, scale=3, size=(y_actual_org.shape[0], 1))\n",
    "y_estimated2 = y_actual_org + np.random.normal(loc=0, scale=4, size=(y_actual_org.shape[0], 1))\n",
    "y_estimated3 = y_actual_org + np.random.normal(loc=0, scale=5, size=(y_actual_org.shape[0], 1))\n",
    "\n",
    "data_list = [\n",
    "    {\"name\": \"Training\", \"actual\": y_actual_org, \"estimated\": y_estimated1},\n",
    "    {\"name\": \"Validation\", \"actual\": y_actual_org, \"estimated\": y_estimated2},\n",
    "    {\"name\": \"Test\", \"actual\": y_actual_org, \"estimated\": y_estimated3},\n",
    "]\n",
    "\n",
    "fig, axes = draw_figures(data_list, \"Training - Validation - Test\")\n",
    "fig.savefig(\"./sample_boston.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
